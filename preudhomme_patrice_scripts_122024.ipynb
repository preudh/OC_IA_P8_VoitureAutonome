{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **1. Importation des bibliothÃ¨ques**",
   "id": "65d48c413aae83d6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "id": "37907a776d9387a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:07:46.705257Z",
     "start_time": "2024-12-17T12:07:43.369480Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install scikit-learn",
   "id": "95c4900aa6d1481a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\pat\\.conda\\envs\\test_env\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:52:25.143868Z",
     "start_time": "2024-12-17T11:40:59.274476Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install tensorflow[and-cuda]",
   "id": "570476d7350587d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Downloading tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "     -------------------------------------- 390.0/390.0 MB 6.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu12==12.5.1.3\n",
      "  Downloading nvidia_cusparse_cu12-12.5.1.3-py3-none-win_amd64.whl (214.7 MB)\n",
      "     -------------------------------------- 214.7/214.7 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.5.82\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-win_amd64.whl (38.7 MB)\n",
      "     --------------------------------------- 38.7/38.7 MB 11.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==9.3.0.75\n",
      "  Downloading nvidia_cudnn_cu12-9.3.0.75-py3-none-win_amd64.whl (574.8 MB)\n",
      "     -------------------------------------- 574.8/574.8 MB 4.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.5.82\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.5.82-py3-none-win_amd64.whl (16.7 MB)\n",
      "     --------------------------------------- 16.7/16.7 MB 12.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu12==12.5.82\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-win_amd64.whl (10.0 MB)\n",
      "     --------------------------------------- 10.0/10.0 MB 13.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.82\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-win_amd64.whl (889 kB)\n",
      "     ---------------------------------------- 889.9/889.9 kB ? eta 0:00:00\n",
      "Collecting nvidia-cufft-cu12==11.2.3.61\n",
      "  Downloading nvidia_cufft_cu12-11.2.3.61-py3-none-win_amd64.whl (191.5 MB)\n",
      "     -------------------------------------- 191.5/191.5 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-curand-cu12==10.3.6.82\n",
      "  Downloading nvidia_curand_cu12-10.3.6.82-py3-none-win_amd64.whl (55.8 MB)\n",
      "     --------------------------------------- 55.8/55.8 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.17.1-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.17.1\n",
      "  Downloading tensorflow_intel-2.17.1-cp310-cp310-win_amd64.whl (382.2 MB)\n",
      "     -------------------------------------- 382.2/382.2 MB 7.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29\n",
      "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-win_amd64.whl (719.4 MB)\n",
      "     -------------------------------------- 719.4/719.4 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-win_amd64.whl (2.0 kB)\n",
      "Collecting tensorflow-intel==2.17.0\n",
      "  Downloading tensorflow_intel-2.17.0-cp310-cp310-win_amd64.whl (385.0 MB)\n",
      "     -------------------------------------- 385.0/385.0 MB 5.1 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.16.2-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.2\n",
      "  Downloading tensorflow_intel-2.16.2-cp310-cp310-win_amd64.whl (376.9 MB)\n",
      "     -------------------------------------- 376.9/376.9 MB 3.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1\n",
      "  Downloading tensorflow_intel-2.16.1-cp310-cp310-win_amd64.whl (376.9 MB)\n",
      "     -------------------------------------- 376.9/376.9 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.15.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.1\n",
      "  Downloading tensorflow_intel-2.15.1-cp310-cp310-win_amd64.whl (300.9 MB)\n",
      "     -------------------------------------- 300.9/300.9 MB 5.2 MB/s eta 0:00:00\n",
      "Collecting nvidia-cublas-cu12==12.2.5.6\n",
      "  Downloading nvidia_cublas_cu12-12.2.5.6-py3-none-win_amd64.whl (450.5 MB)\n",
      "     -------------------------------------- 450.5/450.5 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==8.9.4.25\n",
      "  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-win_amd64.whl (734.8 MB)\n",
      "     -------------------------------------- 734.8/734.8 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufft-cu12==11.0.8.103\n",
      "  Downloading nvidia_cufft_cu12-11.0.8.103-py3-none-win_amd64.whl (99.0 MB)\n",
      "     ---------------------------------------- 99.0/99.0 MB 7.5 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.2.140\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-win_amd64.whl (15.9 MB)\n",
      "     ---------------------------------------- 15.9/15.9 MB 8.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu12==11.5.2.141\n",
      "  Downloading nvidia_cusolver_cu12-11.5.2.141-py3-none-win_amd64.whl (122.2 MB)\n",
      "     -------------------------------------- 122.2/122.2 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu12==12.1.2.141\n",
      "  Downloading nvidia_cusparse_cu12-12.1.2.141-py3-none-win_amd64.whl (194.8 MB)\n",
      "     -------------------------------------- 194.8/194.8 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-curand-cu12==10.3.3.141\n",
      "  Downloading nvidia_curand_cu12-10.3.3.141-py3-none-win_amd64.whl (56.0 MB)\n",
      "     ---------------------------------------- 56.0/56.0 MB 8.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu12==12.2.140\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-win_amd64.whl (842 kB)\n",
      "     ------------------------------------- 842.6/842.6 kB 52.0 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.15.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp310-cp310-win_amd64.whl (300.9 MB)\n",
      "     -------------------------------------- 300.9/300.9 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting tensorrt==8.6.1.post1\n",
      "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.14.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.1\n",
      "  Downloading tensorflow_intel-2.14.1-cp310-cp310-win_amd64.whl (284.1 MB)\n",
      "     -------------------------------------- 284.1/284.1 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu11==11.4.1.48\n",
      "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-win_amd64.whl (125.7 MB)\n",
      "     ------------------------------------- 125.7/125.7 MB 13.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvcc-cu11==11.8.89\n",
      "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-win_amd64.whl (15.7 MB)\n",
      "     ---------------------------------------- 15.7/15.7 MB 8.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu11==11.7.5.86\n",
      "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-win_amd64.whl (203.4 MB)\n",
      "     -------------------------------------- 203.4/203.4 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cublas-cu11==11.11.3.6\n",
      "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-win_amd64.whl (427.2 MB)\n",
      "     -------------------------------------- 427.2/427.2 MB 4.2 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu11==11.8.87\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-win_amd64.whl (10.0 MB)\n",
      "     --------------------------------------- 10.0/10.0 MB 27.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-win_amd64.whl (172.2 MB)\n",
      "     ------------------------------------- 172.2/172.2 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.0\n",
      "  Downloading tensorflow_intel-2.14.0-cp310-cp310-win_amd64.whl (284.1 MB)\n",
      "     -------------------------------------- 284.1/284.1 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.13.1-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.1\n",
      "  Downloading tensorflow_intel-2.13.1-cp310-cp310-win_amd64.whl (276.5 MB)\n",
      "     -------------------------------------- 276.5/276.5 MB 5.4 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22\n",
      "  Downloading numpy-1.24.3-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "     --------------------------------------- 14.8/14.8 MB 24.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (75.6.0)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 105.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.4.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (2.1.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "     ------------------------------------- 413.4/413.4 kB 13.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.68.0)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 71.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.6.3)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "     ------------------------------------- 440.8/440.8 kB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (0.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (24.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (0.45.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "     ------------------------------------- 209.8/209.8 kB 13.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (2.32.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.1.3)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.0.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: typing-extensions, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, keras, gast, cachetools, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.7.0\n",
      "    Uninstalling keras-3.7.0:\n",
      "      Successfully uninstalled keras-3.7.0\n",
      "Successfully installed cachetools-5.5.0 gast-0.4.0 google-auth-2.37.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-2.2.0 oauthlib-3.2.2 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.1 typing-extensions-4.12.2\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\pat\\.conda\\envs\\test_env\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.1 requires fsspec, which is not installed.\n",
      "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "fastapi 0.115.3 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "torch 2.5.1 requires sympy==1.13.1, but you have sympy 1.13.3 which is incompatible.\n",
      "torch 2.5.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "ipython 8.30.0 requires typing_extensions>=4.6; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:38:51.139730Z",
     "start_time": "2024-12-17T12:38:27.995520Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade tensorflow\n",
   "id": "8dee812203f8e972",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (2.13.1)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Using cached tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Collecting numpy<2.1.0,>=1.26.0\n",
      "  Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl (15.9 MB)\n",
      "     --------------------------------------- 15.9/15.9 MB 34.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 59.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: namex in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: rich in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: optree in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: numpy, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.0\n",
      "    Uninstalling numpy-2.2.0:\n",
      "      Successfully uninstalled numpy-2.2.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\pat\\.conda\\envs\\test_env\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] AccÃ¨s refusÃ©: 'C:\\\\Users\\\\pat\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-1ceylgt2\\\\linalg\\\\_umath_linalg.cp310-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Version TensorFlow :\", tf.__version__)\n",
    "print(\"GPU disponible :\", tf.config.list_physical_devices('GPU'))\n"
   ],
   "id": "5e86fa381447add1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# import cv2\n",
    "# import tqdm\n",
    "# from sklearn.metrics import accuracy_score, jaccard_score"
   ],
   "id": "b0d019d21b0005de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **2. PrÃ©paration des donnÃ©es avec GÃ©nÃ©rateurs de Batches**\n",
    " - Dans cette cellule, nous chargeons les images RGB d'origine ainsi que les masques de segmentation Ã  partir des dossiers train, val, et test qui sont dÃ©jÃ  prÃ©parÃ©s. Les images sont redimensionnÃ©es Ã  une taille plus petite (256x256) pour rendre l'entraÃ®nement plus efficace, puis normalisÃ©es.\n",
    "  - Le jeu de donnÃ©es est composÃ© de 2 dossiers:\n",
    "â leftImg8bit : ce dossier contient les images RGB dâorigines. Ce sont les donnÃ©es dâÃ©ntrÃ©e\n",
    "â gtFine : ce dossier contient les masques de segmentation. Ce sont les donnÃ©es de sortie\n",
    "- En ce qui concerne les donnÃ©es de sortie, il y a plusieurs types de fichiers, mais nous ne nous intÃ©resserons quâaux\n",
    "fichiers dont le nom se termine par â_labelIds.pngâ. Ce sont les masques correspondant aux images\n",
    "RGB."
   ],
   "id": "e5676f8005654089"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:24:24.673443Z",
     "start_time": "2024-12-17T12:24:24.565807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# DÃ©finitions des chemins de fichiers avec chemins relatifs\n",
    "base_dir = os.path.join(os.getcwd(), 'data')\n",
    "image_dir_train = os.path.join(base_dir, 'leftImg8bit/train')\n",
    "mask_dir_train = os.path.join(base_dir, 'gtFine/train')\n",
    "image_dir_val = os.path.join(base_dir, 'leftImg8bit/val')\n",
    "mask_dir_val = os.path.join(base_dir, 'gtFine/val')\n",
    "image_dir_test = os.path.join(base_dir, 'leftImg8bit/test')\n",
    "mask_dir_test = os.path.join(base_dir, 'gtFine/test')\n",
    "\n",
    "# GÃ©nÃ©rateur de donnÃ©es pour charger les images par batch\n",
    "# GÃ©nÃ©rateur de donnÃ©es pour charger les images par batch\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, image_dir, mask_dir, batch_size=16, img_size=(256, 256)):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.image_list = []\n",
    "\n",
    "        # Parcours rÃ©cursif des dossiers pour les images\n",
    "        for root, _, files in os.walk(image_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.image_list.append(os.path.join(root, file))\n",
    "\n",
    "        # Parcours rÃ©cursif des dossiers pour les masques (uniquement `_labelIds.png`)\n",
    "        self.mask_list = []\n",
    "        for root, _, files in os.walk(mask_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('_labelIds.png'):\n",
    "                    self.mask_list.append(os.path.join(root, file))\n",
    "\n",
    "        # S'assurer que les listes sont triÃ©es pour que chaque image corresponde au bon masque\n",
    "        self.image_list.sort()\n",
    "        self.mask_list.sort()\n",
    "\n",
    "        self.indexes = np.arange(len(self.image_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images, masks = [], []\n",
    "\n",
    "        for i in batch_indexes:\n",
    "            img_path = self.image_list[i]\n",
    "            mask_path = self.mask_list[i]\n",
    "            img = image.load_img(img_path, target_size=self.img_size)\n",
    "            img = image.img_to_array(img) / 255.0\n",
    "            mask = image.load_img(mask_path, color_mode=\"grayscale\", target_size=self.img_size)\n",
    "            mask = image.img_to_array(mask) / 255.0\n",
    "\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "\n",
    "        return np.array(images), np.array(masks)\n",
    "\n",
    "\n",
    "# CrÃ©ation des gÃ©nÃ©rateurs de donnÃ©es pour train, validation et test\n",
    "batch_size = 16\n",
    "train_gen = DataGenerator(image_dir_train, mask_dir_train, batch_size=batch_size)\n",
    "val_gen = DataGenerator(image_dir_val, mask_dir_val, batch_size=batch_size)\n",
    "test_gen = DataGenerator(image_dir_test, mask_dir_test, batch_size=batch_size)\n"
   ],
   "id": "8b1bd2d9dd815da3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:24:33.284017Z",
     "start_time": "2024-12-17T12:24:33.271499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Nombre d'images dans le dossier d'entraÃ®nement : {len(train_gen.image_list)}\")\n",
    "print(f\"Nombre de masques dans le dossier d'entraÃ®nement : {len(train_gen.mask_list)}\")\n"
   ],
   "id": "1d7946b841e63cfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images dans le dossier d'entraÃ®nement : 2975\n",
      "Nombre de masques dans le dossier d'entraÃ®nement : 2975\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:02:42.778824Z",
     "start_time": "2024-12-17T12:02:42.556669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for images, masks in train_gen:\n",
    "    print(images.shape, masks.shape)\n",
    "    break\n"
   ],
   "id": "e8b4441ed0457e81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 256, 256, 3) (2, 256, 256, 1)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **3. DÃ©veloppement et entraÃ®nement du modÃ¨le U-Net:**",
   "id": "fbbe2a512296964c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Explication :** Cette cellule contient la dÃ©finition et la construction du modÃ¨le U-Net. Le modÃ¨le est entraÃ®nÃ© sur les donnÃ©es divisÃ©es avec 10 epochs. U-Net est bien adaptÃ© Ã  la segmentation d'images. Des callbacks ont Ã©tÃ© ajoutÃ©s pour effectuer un early stopping et sauvegarder le meilleur modÃ¨le.\n",
   "id": "e1ded030d16e4db6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Option 1: Placer la construction du modÃ¨le et l'entraÃ®nement sur le CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    # Function to build the U-Net model\n",
    "    def unet_model(input_size=(256, 256, 3)):\n",
    "        inputs = Input(input_size)\n",
    "\n",
    "        # Downsampling path\n",
    "        c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "        c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "        p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "        # Bottom (bottleneck)\n",
    "        c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "\n",
    "        # Upsampling path\n",
    "        u4 = UpSampling2D((2, 2))(c3)\n",
    "        u4 = concatenate([u4, c2])\n",
    "\n",
    "        u5 = UpSampling2D((2, 2))(u4)\n",
    "        u5 = concatenate([u5, c1])\n",
    "\n",
    "        c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u5)\n",
    "        outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "\n",
    "        model = Model(inputs=[inputs], outputs=[outputs])\n",
    "        return model\n",
    "\n",
    "    # Compile the model\n",
    "    model = unet_model()\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping and model checkpoint\n",
    "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "    model_checkpoint = ModelCheckpoint(os.path.join('models', 'best_model.keras'), save_best_only=True, monitor='val_loss')\n",
    "\n",
    "    # Training the model on CPU\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=10,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n"
   ],
   "id": "b5f1a5502a94693b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **4.  Comparaison des ModÃ¨les U-Net, VGG16-UNET, et U-Net Mini**",
   "id": "63bf1b5becc0baee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Explication :** Ici, nous avons ajoutÃ© un modÃ¨le U-Net Mini, qui est une version plus lÃ©gÃ¨re et simplifiÃ©e du U-Net. Le modÃ¨le VGG16-UNET a Ã©tÃ© mis Ã  jour pour inclure une couche de data augmentation interne afin de mieux gÃ©nÃ©raliser les performances.\n",
   "id": "4a679e3d2450a87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Importation des bibliothÃ¨ques nÃ©cessaires\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, RandomZoom, Conv2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# DÃ©sactiver complÃ¨tement les GPU pour exÃ©cuter uniquement sur le CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# DÃ©veloppement du modÃ¨le VGG16-UNET\n",
    "def vgg16_unet_model(input_size=(256, 256, 3)):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_size)\n",
    "    \n",
    "    # Data augmentation intÃ©grÃ©e\n",
    "    inputs = Input(input_size)\n",
    "    x = RandomFlip(\"horizontal\")(inputs)\n",
    "    x = RandomRotation(0.2)(x)\n",
    "    x = RandomZoom(0.2)(x)\n",
    "    \n",
    "    # Passage de l'entrÃ©e dans le modÃ¨le VGG16\n",
    "    block1_conv2 = base_model.get_layer('block1_conv2').output\n",
    "    block2_conv2 = base_model.get_layer('block2_conv2').output\n",
    "    block3_conv3 = base_model.get_layer('block3_conv3').output\n",
    "    vgg_outputs = [block1_conv2, block2_conv2, block3_conv3]\n",
    "    \n",
    "    # DÃ©finir un nouveau modÃ¨le avec les sorties intermÃ©diaires dÃ©sirÃ©es\n",
    "    vgg16_encoder = Model(inputs=base_model.input, outputs=vgg_outputs)\n",
    "    \n",
    "    # Passer les images par l'encodeur\n",
    "    c1, c2, c3 = vgg16_encoder(x)\n",
    "    \n",
    "    # Partie remontante du U-Net avec des couches de dÃ©codage\n",
    "    u4 = UpSampling2D((2, 2))(c3)\n",
    "    u4 = concatenate([u4, c2])\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(u4)\n",
    "    \n",
    "    u5 = UpSampling2D((2, 2))(c4)\n",
    "    u5 = concatenate([u5, c1])\n",
    "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u5)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialisation et compilation du modÃ¨le\n",
    "vgg16_model = vgg16_unet_model()\n",
    "vgg16_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# DÃ©finition des callbacks\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "vgg16_checkpoint = ModelCheckpoint(os.path.join('models', 'vgg16_best_model.keras'), save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# EntraÃ®nement du modÃ¨le VGG16-UNET uniquement sur le CPU\n",
    "def train_vgg16_on_cpu():\n",
    "    with tf.device('/CPU:0'):  # SpÃ©cifie l'utilisation explicite du CPU\n",
    "        vgg16_model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=10,\n",
    "            callbacks=[early_stopping, vgg16_checkpoint]\n",
    "        )\n",
    "\n",
    "# Appel de la fonction d'entraÃ®nement\n",
    "train_vgg16_on_cpu()\n"
   ],
   "id": "37abad2a56578448"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T18:04:00.039825100Z",
     "start_time": "2024-12-07T09:59:15.642864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# DÃ©veloppement du modÃ¨le U-Net Mini\n",
    "def unet_mini_model(input_size=(256, 256, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Partie Ã  la descente\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "\n",
    "    # Partie remontante\n",
    "    u4 = UpSampling2D((2, 2))(c3)\n",
    "    u4 = concatenate([u4, c2])\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(u4)\n",
    "\n",
    "    u5 = UpSampling2D((2, 2))(c4)\n",
    "    u5 = concatenate([u5, c1])\n",
    "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(u5)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "unet_mini_model = unet_mini_model()\n",
    "unet_mini_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# EntraÃ®nement du modÃ¨le U-Net Mini\n",
    "def train_unet_mini_on_gpu():\n",
    "    with tf.device('/GPU:0'):\n",
    "        unet_mini_model.fit(train_gen, validation_data=val_gen, epochs=10, callbacks=[early_stopping, unet_mini_checkpoint])\n",
    "        \n",
    "unet_mini_model()        "
   ],
   "id": "475e859f6c01d268",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Conclusion, Comparaison et Visualisation des ModÃ¨les",
   "id": "2c159dc8ff591131"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "** Cette cellule compare les trois modÃ¨les entraÃ®nÃ©s (U-Net classique, VGG16-UNET, et U-Net Mini) sur les mÃ©triques telles que l'accuracy, l'IoU, et le Dice Coefficient. Des graphiques sont crÃ©Ã©s pour visualiser les performances de chaque modÃ¨le. ",
   "id": "902b1c9cc27a68a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:04:02.278031Z",
     "start_time": "2024-12-17T12:04:02.266120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# VÃ©rification des gÃ©nÃ©rateurs\n",
    "print(f\"Nombre d'images dans test_gen : {len(test_gen)}\")\n",
    "print(f\"Nombre d'images dans val_gen : {len(val_gen)}\")\n",
    "\n",
    "# Si le gÃ©nÃ©rateur a des listes d'images et de masques, vÃ©rifie leur longueur\n",
    "if hasattr(test_gen, 'image_list') and hasattr(test_gen, 'mask_list'):\n",
    "    print(f\"Nombre d'images dans test_gen : {len(test_gen.image_list)}\")\n",
    "    print(f\"Nombre de masques dans test_gen : {len(test_gen.mask_list)}\")\n",
    "\n",
    "if hasattr(val_gen, 'image_list') and hasattr(val_gen, 'mask_list'):\n",
    "    print(f\"Nombre d'images dans val_gen : {len(val_gen.image_list)}\")\n",
    "    print(f\"Nombre de masques dans val_gen : {len(val_gen.mask_list)}\")"
   ],
   "id": "15408012575e3476",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images dans test_gen : 762\n",
      "Nombre d'images dans val_gen : 250\n",
      "Nombre d'images dans test_gen : 1525\n",
      "Nombre de masques dans test_gen : 1153\n",
      "Nombre d'images dans val_gen : 500\n",
      "Nombre de masques dans val_gen : 500\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "!pip show tensorflow keras\n",
   "id": "16b1ddcfa166a2f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:11:06.282100Z",
     "start_time": "2024-12-17T12:11:05.843871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# Charger les modÃ¨les sauvegardÃ©s\n",
    "unet_model_path = os.path.join('models', 'unet_best_model.keras')\n",
    "vgg16_model_path = os.path.join('models', 'vgg16_best_model.keras')\n",
    "unet_mini_model_path = os.path.join('models', 'unet_mini_best_model.keras')\n",
    "\n",
    "# VÃ©rifier que les fichiers existent\n",
    "assert os.path.exists(unet_model_path), f\"Le modÃ¨le U-Net n'a pas Ã©tÃ© trouvÃ© Ã  {unet_model_path}\"\n",
    "assert os.path.exists(vgg16_model_path), f\"Le modÃ¨le VGG16-UNET n'a pas Ã©tÃ© trouvÃ© Ã  {vgg16_model_path}\"\n",
    "assert os.path.exists(unet_mini_model_path), f\"Le modÃ¨le U-Net Mini n'a pas Ã©tÃ© trouvÃ© Ã  {unet_mini_model_path}\"\n",
    "\n",
    "# Charger les modÃ¨les\n",
    "unet_model = load_model(unet_model_path)\n",
    "vgg16_model = load_model(vgg16_model_path)\n",
    "unet_mini_model = load_model(unet_mini_model_path)\n",
    "\n",
    "# Comparaison des performances des modÃ¨les\n",
    "def compare_models(models, val_gen, test_gen):\n",
    "    metrics = []\n",
    "    for model in models:\n",
    "        # Nom du modÃ¨le\n",
    "        model_name = model.name if hasattr(model, 'name') else 'Unnamed Model'\n",
    "\n",
    "        # Ãvaluation sur l'ensemble de validation\n",
    "        print(f\"Ãvaluation sur l'ensemble de validation pour le modÃ¨le: {model_name}\")\n",
    "        loss, accuracy = model.evaluate(val_gen, verbose=0)\n",
    "\n",
    "        # PrÃ©dictions sur l'ensemble de test\n",
    "        print(f\"PrÃ©dictions sur l'ensemble de test pour le modÃ¨le: {model_name}\")\n",
    "        y_pred = model.predict(test_gen, verbose=0)\n",
    "        y_pred_binary = (y_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "        # RÃ©cupÃ©rer les vraies Ã©tiquettes de l'ensemble de test\n",
    "        y_test = np.concatenate([y for _, y in test_gen], axis=0)\n",
    "\n",
    "        # Calcul de l'IoU (Intersection over Union)\n",
    "        intersection = np.logical_and(y_test, y_pred_binary).sum()\n",
    "        union = np.logical_or(y_test, y_pred_binary).sum()\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "\n",
    "        # Calcul du coefficient de Dice\n",
    "        dice = (2 * intersection) / (y_test.sum() + y_pred_binary.sum()) if (y_test.sum() + y_pred_binary.sum()) > 0 else 0\n",
    "\n",
    "        # Ajouter les mÃ©triques du modÃ¨le Ã  la liste\n",
    "        metrics.append({\n",
    "            'model': model_name,\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy,\n",
    "            'iou': iou,\n",
    "            'dice': dice\n",
    "        })\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Liste des modÃ¨les Ã  comparer\n",
    "models = [unet_model, vgg16_model, unet_mini_model]\n",
    "\n",
    "# Comparer les modÃ¨les\n",
    "metrics = compare_models(models, val_gen, test_gen)\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(\"\\nRÃ©sumÃ© des performances des modÃ¨les :\")\n",
    "for metric in metrics:\n",
    "    print(f\"Model: {metric['model']}\")\n",
    "    print(f\"  Loss: {metric['loss']:.4f}\")\n",
    "    print(f\"  Accuracy: {metric['accuracy']:.4f}\")\n",
    "    print(f\"  IoU: {metric['iou']:.4f}\")\n",
    "    print(f\"  Dice: {metric['dice']:.4f}\")"
   ],
   "id": "80d30139eb3920b9",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not deserialize class 'Functional' because its parent module keras.src.models.functional cannot be imported. Full object config: {'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional_1', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 256, 256, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}, 'registered_name': None, 'name': 'input_layer_1', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 3]}, 'name': 'conv2d_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 3], 'dtype': 'float32', 'keras_history': ['input_layer_1', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 16]}, 'name': 'max_pooling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 16]}, 'name': 'conv2d_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 16], 'dtype': 'float32', 'keras_history': ['max_pooling2d_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 32]}, 'name': 'max_pooling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64, 32]}, 'name': 'conv2d_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 64, 64, 32], 'dtype': 'float32', 'keras_history': ['max_pooling2d_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'UpSampling2D', 'config': {'name': 'up_sampling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'size': [2, 2], 'data_format': 'channels_last', 'interpolation': 'nearest'}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64, 128]}, 'name': 'up_sampling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 64, 64, 128], 'dtype': 'float32', 'keras_history': ['conv2d_8', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 128, 128, 128], [None, 128, 128, 32]]}, 'name': 'concatenate_2', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 128], 'dtype': 'float32', 'keras_history': ['up_sampling2d_2', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 160]}, 'name': 'conv2d_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 160], 'dtype': 'float32', 'keras_history': ['concatenate_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'UpSampling2D', 'config': {'name': 'up_sampling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'size': [2, 2], 'data_format': 'channels_last', 'interpolation': 'nearest'}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 32]}, 'name': 'up_sampling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_9', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 256, 256, 32], [None, 256, 256, 16]]}, 'name': 'concatenate_3', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 32], 'dtype': 'float32', 'keras_history': ['up_sampling2d_3', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 48]}, 'name': 'conv2d_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 48], 'dtype': 'float32', 'keras_history': ['concatenate_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 1, 'kernel_size': [1, 1], 'strides': [1, 1], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 16]}, 'name': 'conv2d_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_10', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer_1', 0, 0]], 'output_layers': [['conv2d_11', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'binary_crossentropy', 'loss_weights': None, 'metrics': ['accuracy'], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:776\u001B[0m, in \u001B[0;36m_retrieve_class_or_fn\u001B[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001B[0m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 776\u001B[0m     mod \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1050\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1004\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'keras.src.models.functional'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(unet_mini_model_path), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLe modÃ¨le U-Net Mini n\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma pas Ã©tÃ© trouvÃ© Ã  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00munet_mini_model_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Charger les modÃ¨les\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m unet_model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43munet_model_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m vgg16_model \u001B[38;5;241m=\u001B[39m load_model(vgg16_model_path)\n\u001B[0;32m     18\u001B[0m unet_mini_model \u001B[38;5;241m=\u001B[39m load_model(unet_mini_model_path)\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:230\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[0;32m    226\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    227\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe following argument(s) are not supported \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    228\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith the native Keras format: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    229\u001B[0m         )\n\u001B[1;32m--> 230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msaving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m        \u001B[49m\u001B[43msafe_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m legacy_sm_saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    239\u001B[0m     filepath, custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects, \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    240\u001B[0m )\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:275\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    272\u001B[0m             asset_store\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 275\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    276\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:240\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;66;03m# Construct the model from the configuration file in the archive.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ObjectSharingScope():\n\u001B[1;32m--> 240\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_mode\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    244\u001B[0m all_filenames \u001B[38;5;241m=\u001B[39m zf\u001B[38;5;241m.\u001B[39mnamelist()\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _VARS_FNAME \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m all_filenames:\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:681\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[1;34m(config, custom_objects, safe_mode, **kwargs)\u001B[0m\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    679\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[1;32m--> 681\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43m_retrieve_class_or_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    682\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    683\u001B[0m \u001B[43m    \u001B[49m\u001B[43mregistered_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    684\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mclass\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    686\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfull_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    688\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mcls\u001B[39m, types\u001B[38;5;241m.\u001B[39mFunctionType):\n\u001B[0;32m    691\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:778\u001B[0m, in \u001B[0;36m_retrieve_class_or_fn\u001B[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001B[0m\n\u001B[0;32m    776\u001B[0m     mod \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(module)\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n\u001B[1;32m--> 778\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    779\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not deserialize \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobj_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m because \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    780\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mits parent module \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m cannot be imported. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    781\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFull object config: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_config\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    782\u001B[0m     )\n\u001B[0;32m    783\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mvars\u001B[39m(mod)\u001B[38;5;241m.\u001B[39mget(name, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    785\u001B[0m \u001B[38;5;66;03m# Special case for keras.metrics.metrics\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: Could not deserialize class 'Functional' because its parent module keras.src.models.functional cannot be imported. Full object config: {'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional_1', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 256, 256, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}, 'registered_name': None, 'name': 'input_layer_1', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 3]}, 'name': 'conv2d_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 3], 'dtype': 'float32', 'keras_history': ['input_layer_1', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 16]}, 'name': 'max_pooling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 16]}, 'name': 'conv2d_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 16], 'dtype': 'float32', 'keras_history': ['max_pooling2d_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 32]}, 'name': 'max_pooling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64, 32]}, 'name': 'conv2d_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 64, 64, 32], 'dtype': 'float32', 'keras_history': ['max_pooling2d_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'UpSampling2D', 'config': {'name': 'up_sampling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'size': [2, 2], 'data_format': 'channels_last', 'interpolation': 'nearest'}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64, 128]}, 'name': 'up_sampling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 64, 64, 128], 'dtype': 'float32', 'keras_history': ['conv2d_8', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 128, 128, 128], [None, 128, 128, 32]]}, 'name': 'concatenate_2', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 128], 'dtype': 'float32', 'keras_history': ['up_sampling2d_2', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 160]}, 'name': 'conv2d_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 160], 'dtype': 'float32', 'keras_history': ['concatenate_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'UpSampling2D', 'config': {'name': 'up_sampling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'size': [2, 2], 'data_format': 'channels_last', 'interpolation': 'nearest'}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 32]}, 'name': 'up_sampling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_9', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 256, 256, 32], [None, 256, 256, 16]]}, 'name': 'concatenate_3', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 32], 'dtype': 'float32', 'keras_history': ['up_sampling2d_3', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 48]}, 'name': 'conv2d_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 48], 'dtype': 'float32', 'keras_history': ['concatenate_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 1, 'kernel_size': [1, 1], 'strides': [1, 1], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 16]}, 'name': 'conv2d_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_10', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer_1', 0, 0]], 'output_layers': [['conv2d_11', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'binary_crossentropy', 'loss_weights': None, 'metrics': ['accuracy'], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualisation des rÃ©sultats\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(metrics_df['model'], metrics_df['accuracy'], label='Accuracy', marker='o')\n",
    "plt.plot(metrics_df['model'], metrics_df['iou'], label='IoU', marker='o')\n",
    "plt.plot(metrics_df['model'], metrics_df['dice'], label='Dice Coefficient', marker='o')\n",
    "plt.title('Comparaison des mÃ©triques entre modÃ¨les')\n",
    "plt.xlabel('ModÃ¨les')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(metrics_df['model'], metrics_df['loss'], color='red')\n",
    "plt.title('Loss des diffÃ©rents modÃ¨les')\n",
    "plt.xlabel('ModÃ¨les')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "id": "74f61c9f0a7f5089"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualisation des exemples de rÃ©sultats pour chaque modÃ¨le",
   "id": "6b639662d5040db4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fonction de visualisation des prÃ©dictions\n",
    "\n",
    "def visualize_predictions(models, test_gen, num_examples=3):\n",
    "    for model in models:\n",
    "        print(f\"Visualisation des prÃ©dictions pour le modÃ¨le: {model.name}\")\n",
    "        predictions = model.predict(test_gen)\n",
    "        X_test, y_test = next(iter(test_gen))\n",
    "        for i in range(num_examples):\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(X_test[i])\n",
    "            plt.title(\"Image d'origine\")\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(y_test[i].squeeze(), cmap='gray')\n",
    "            plt.title(\"Masque rÃ©el\")\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "            plt.title(\"Masque prÃ©dit\")\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "# Visualiser quelques exemples de segmentation\n",
    "visualize_predictions(models, test_gen)"
   ],
   "id": "edd80304a6ea4d2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
