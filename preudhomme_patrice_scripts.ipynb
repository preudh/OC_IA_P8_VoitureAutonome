{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **1. Importation des bibliothèques**",
   "id": "65d48c413aae83d6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "id": "37907a776d9387a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:07:46.705257Z",
     "start_time": "2024-12-17T12:07:43.369480Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install scikit-learn",
   "id": "95c4900aa6d1481a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\pat\\.conda\\envs\\test_env\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:52:25.143868Z",
     "start_time": "2024-12-17T11:40:59.274476Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install tensorflow[and-cuda]",
   "id": "570476d7350587d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Downloading tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "     -------------------------------------- 390.0/390.0 MB 6.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu12==12.5.1.3\n",
      "  Downloading nvidia_cusparse_cu12-12.5.1.3-py3-none-win_amd64.whl (214.7 MB)\n",
      "     -------------------------------------- 214.7/214.7 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.5.82\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-win_amd64.whl (38.7 MB)\n",
      "     --------------------------------------- 38.7/38.7 MB 11.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==9.3.0.75\n",
      "  Downloading nvidia_cudnn_cu12-9.3.0.75-py3-none-win_amd64.whl (574.8 MB)\n",
      "     -------------------------------------- 574.8/574.8 MB 4.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.5.82\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.5.82-py3-none-win_amd64.whl (16.7 MB)\n",
      "     --------------------------------------- 16.7/16.7 MB 12.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu12==12.5.82\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-win_amd64.whl (10.0 MB)\n",
      "     --------------------------------------- 10.0/10.0 MB 13.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.82\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-win_amd64.whl (889 kB)\n",
      "     ---------------------------------------- 889.9/889.9 kB ? eta 0:00:00\n",
      "Collecting nvidia-cufft-cu12==11.2.3.61\n",
      "  Downloading nvidia_cufft_cu12-11.2.3.61-py3-none-win_amd64.whl (191.5 MB)\n",
      "     -------------------------------------- 191.5/191.5 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-curand-cu12==10.3.6.82\n",
      "  Downloading nvidia_curand_cu12-10.3.6.82-py3-none-win_amd64.whl (55.8 MB)\n",
      "     --------------------------------------- 55.8/55.8 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.17.1-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.17.1\n",
      "  Downloading tensorflow_intel-2.17.1-cp310-cp310-win_amd64.whl (382.2 MB)\n",
      "     -------------------------------------- 382.2/382.2 MB 7.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29\n",
      "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-win_amd64.whl (719.4 MB)\n",
      "     -------------------------------------- 719.4/719.4 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-win_amd64.whl (2.0 kB)\n",
      "Collecting tensorflow-intel==2.17.0\n",
      "  Downloading tensorflow_intel-2.17.0-cp310-cp310-win_amd64.whl (385.0 MB)\n",
      "     -------------------------------------- 385.0/385.0 MB 5.1 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.16.2-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.2\n",
      "  Downloading tensorflow_intel-2.16.2-cp310-cp310-win_amd64.whl (376.9 MB)\n",
      "     -------------------------------------- 376.9/376.9 MB 3.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1\n",
      "  Downloading tensorflow_intel-2.16.1-cp310-cp310-win_amd64.whl (376.9 MB)\n",
      "     -------------------------------------- 376.9/376.9 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.15.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.1\n",
      "  Downloading tensorflow_intel-2.15.1-cp310-cp310-win_amd64.whl (300.9 MB)\n",
      "     -------------------------------------- 300.9/300.9 MB 5.2 MB/s eta 0:00:00\n",
      "Collecting nvidia-cublas-cu12==12.2.5.6\n",
      "  Downloading nvidia_cublas_cu12-12.2.5.6-py3-none-win_amd64.whl (450.5 MB)\n",
      "     -------------------------------------- 450.5/450.5 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==8.9.4.25\n",
      "  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-win_amd64.whl (734.8 MB)\n",
      "     -------------------------------------- 734.8/734.8 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufft-cu12==11.0.8.103\n",
      "  Downloading nvidia_cufft_cu12-11.0.8.103-py3-none-win_amd64.whl (99.0 MB)\n",
      "     ---------------------------------------- 99.0/99.0 MB 7.5 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.2.140\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-win_amd64.whl (15.9 MB)\n",
      "     ---------------------------------------- 15.9/15.9 MB 8.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu12==11.5.2.141\n",
      "  Downloading nvidia_cusolver_cu12-11.5.2.141-py3-none-win_amd64.whl (122.2 MB)\n",
      "     -------------------------------------- 122.2/122.2 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu12==12.1.2.141\n",
      "  Downloading nvidia_cusparse_cu12-12.1.2.141-py3-none-win_amd64.whl (194.8 MB)\n",
      "     -------------------------------------- 194.8/194.8 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-curand-cu12==10.3.3.141\n",
      "  Downloading nvidia_curand_cu12-10.3.3.141-py3-none-win_amd64.whl (56.0 MB)\n",
      "     ---------------------------------------- 56.0/56.0 MB 8.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu12==12.2.140\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-win_amd64.whl (842 kB)\n",
      "     ------------------------------------- 842.6/842.6 kB 52.0 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.15.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp310-cp310-win_amd64.whl (300.9 MB)\n",
      "     -------------------------------------- 300.9/300.9 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting tensorrt==8.6.1.post1\n",
      "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.14.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.1\n",
      "  Downloading tensorflow_intel-2.14.1-cp310-cp310-win_amd64.whl (284.1 MB)\n",
      "     -------------------------------------- 284.1/284.1 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu11==11.4.1.48\n",
      "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-win_amd64.whl (125.7 MB)\n",
      "     ------------------------------------- 125.7/125.7 MB 13.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvcc-cu11==11.8.89\n",
      "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-win_amd64.whl (15.7 MB)\n",
      "     ---------------------------------------- 15.7/15.7 MB 8.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu11==11.7.5.86\n",
      "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-win_amd64.whl (203.4 MB)\n",
      "     -------------------------------------- 203.4/203.4 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cublas-cu11==11.11.3.6\n",
      "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-win_amd64.whl (427.2 MB)\n",
      "     -------------------------------------- 427.2/427.2 MB 4.2 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu11==11.8.87\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-win_amd64.whl (10.0 MB)\n",
      "     --------------------------------------- 10.0/10.0 MB 27.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-win_amd64.whl (172.2 MB)\n",
      "     ------------------------------------- 172.2/172.2 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.0\n",
      "  Downloading tensorflow_intel-2.14.0-cp310-cp310-win_amd64.whl (284.1 MB)\n",
      "     -------------------------------------- 284.1/284.1 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.13.1-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.1\n",
      "  Downloading tensorflow_intel-2.13.1-cp310-cp310-win_amd64.whl (276.5 MB)\n",
      "     -------------------------------------- 276.5/276.5 MB 5.4 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22\n",
      "  Downloading numpy-1.24.3-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "     --------------------------------------- 14.8/14.8 MB 24.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (75.6.0)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 105.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.4.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (2.1.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "     ------------------------------------- 413.4/413.4 kB 13.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.68.0)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 71.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.6.3)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "     ------------------------------------- 440.8/440.8 kB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (0.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.1->tensorflow[and-cuda]) (24.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (0.45.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "     ------------------------------------- 209.8/209.8 kB 13.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (2.32.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.1.3)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow[and-cuda]) (3.0.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: typing-extensions, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, keras, gast, cachetools, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.7.0\n",
      "    Uninstalling keras-3.7.0:\n",
      "      Successfully uninstalled keras-3.7.0\n",
      "Successfully installed cachetools-5.5.0 gast-0.4.0 google-auth-2.37.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-2.2.0 oauthlib-3.2.2 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.1 typing-extensions-4.12.2\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\pat\\.conda\\envs\\test_env\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.1 requires fsspec, which is not installed.\n",
      "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "fastapi 0.115.3 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "torch 2.5.1 requires sympy==1.13.1, but you have sympy 1.13.3 which is incompatible.\n",
      "torch 2.5.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "ipython 8.30.0 requires typing_extensions>=4.6; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:38:51.139730Z",
     "start_time": "2024-12-17T12:38:27.995520Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade tensorflow\n",
   "id": "8dee812203f8e972",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (2.13.1)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Using cached tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Collecting numpy<2.1.0,>=1.26.0\n",
      "  Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl (15.9 MB)\n",
      "     --------------------------------------- 15.9/15.9 MB 34.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 59.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: namex in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: rich in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: optree in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pat\\.conda\\envs\\test_env\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pat\\appdata\\roaming\\python\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: numpy, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.0\n",
      "    Uninstalling numpy-2.2.0:\n",
      "      Successfully uninstalled numpy-2.2.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\pat\\.conda\\envs\\test_env\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accès refusé: 'C:\\\\Users\\\\pat\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-1ceylgt2\\\\linalg\\\\_umath_linalg.cp310-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Version TensorFlow :\", tf.__version__)\n",
    "print(\"GPU disponible :\", tf.config.list_physical_devices('GPU'))\n"
   ],
   "id": "5e86fa381447add1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# import cv2\n",
    "# import tqdm\n",
    "# from sklearn.metrics import accuracy_score, jaccard_score"
   ],
   "id": "b0d019d21b0005de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **2. Préparation des données avec Générateurs de Batches**\n",
    " - Dans cette cellule, nous chargeons les images RGB d'origine ainsi que les masques de segmentation à partir des dossiers train, val, et test qui sont déjà préparés. Les images sont redimensionnées à une taille plus petite (256x256) pour rendre l'entraînement plus efficace, puis normalisées.\n",
    "  - Le jeu de données est composé de 2 dossiers:\n",
    "● leftImg8bit : ce dossier contient les images RGB d’origines. Ce sont les données d’éntrée\n",
    "● gtFine : ce dossier contient les masques de segmentation. Ce sont les données de sortie\n",
    "- En ce qui concerne les données de sortie, il y a plusieurs types de fichiers, mais nous ne nous intéresserons qu’aux\n",
    "fichiers dont le nom se termine par “_labelIds.png”. Ce sont les masques correspondant aux images\n",
    "RGB."
   ],
   "id": "e5676f8005654089"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:24:24.673443Z",
     "start_time": "2024-12-17T12:24:24.565807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Définitions des chemins de fichiers avec chemins relatifs\n",
    "base_dir = os.path.join(os.getcwd(), 'data')\n",
    "image_dir_train = os.path.join(base_dir, 'leftImg8bit/train')\n",
    "mask_dir_train = os.path.join(base_dir, 'gtFine/train')\n",
    "image_dir_val = os.path.join(base_dir, 'leftImg8bit/val')\n",
    "mask_dir_val = os.path.join(base_dir, 'gtFine/val')\n",
    "image_dir_test = os.path.join(base_dir, 'leftImg8bit/test')\n",
    "mask_dir_test = os.path.join(base_dir, 'gtFine/test')\n",
    "\n",
    "# Générateur de données pour charger les images par batch\n",
    "# Générateur de données pour charger les images par batch\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, image_dir, mask_dir, batch_size=16, img_size=(256, 256)):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.image_list = []\n",
    "\n",
    "        # Parcours récursif des dossiers pour les images\n",
    "        for root, _, files in os.walk(image_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.image_list.append(os.path.join(root, file))\n",
    "\n",
    "        # Parcours récursif des dossiers pour les masques (uniquement `_labelIds.png`)\n",
    "        self.mask_list = []\n",
    "        for root, _, files in os.walk(mask_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('_labelIds.png'):\n",
    "                    self.mask_list.append(os.path.join(root, file))\n",
    "\n",
    "        # S'assurer que les listes sont triées pour que chaque image corresponde au bon masque\n",
    "        self.image_list.sort()\n",
    "        self.mask_list.sort()\n",
    "\n",
    "        self.indexes = np.arange(len(self.image_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images, masks = [], []\n",
    "\n",
    "        for i in batch_indexes:\n",
    "            img_path = self.image_list[i]\n",
    "            mask_path = self.mask_list[i]\n",
    "            img = image.load_img(img_path, target_size=self.img_size)\n",
    "            img = image.img_to_array(img) / 255.0\n",
    "            mask = image.load_img(mask_path, color_mode=\"grayscale\", target_size=self.img_size)\n",
    "            mask = image.img_to_array(mask) / 255.0\n",
    "\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "\n",
    "        return np.array(images), np.array(masks)\n",
    "\n",
    "\n",
    "# Création des générateurs de données pour train, validation et test\n",
    "batch_size = 16\n",
    "train_gen = DataGenerator(image_dir_train, mask_dir_train, batch_size=batch_size)\n",
    "val_gen = DataGenerator(image_dir_val, mask_dir_val, batch_size=batch_size)\n",
    "test_gen = DataGenerator(image_dir_test, mask_dir_test, batch_size=batch_size)\n"
   ],
   "id": "8b1bd2d9dd815da3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:24:33.284017Z",
     "start_time": "2024-12-17T12:24:33.271499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Nombre d'images dans le dossier d'entraînement : {len(train_gen.image_list)}\")\n",
    "print(f\"Nombre de masques dans le dossier d'entraînement : {len(train_gen.mask_list)}\")\n"
   ],
   "id": "1d7946b841e63cfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images dans le dossier d'entraînement : 2975\n",
      "Nombre de masques dans le dossier d'entraînement : 2975\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:02:42.778824Z",
     "start_time": "2024-12-17T12:02:42.556669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for images, masks in train_gen:\n",
    "    print(images.shape, masks.shape)\n",
    "    break\n"
   ],
   "id": "e8b4441ed0457e81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 256, 256, 3) (2, 256, 256, 1)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **3. Développement et entraînement du modèle U-Net:**",
   "id": "fbbe2a512296964c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Explication :** Cette cellule contient la définition et la construction du modèle U-Net. Le modèle est entraîné sur les données divisées avec 10 epochs. U-Net est bien adapté à la segmentation d'images. Des callbacks ont été ajoutés pour effectuer un early stopping et sauvegarder le meilleur modèle.\n",
   "id": "e1ded030d16e4db6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Option 1: Placer la construction du modèle et l'entraînement sur le CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    # Function to build the U-Net model\n",
    "    def unet_model(input_size=(256, 256, 3)):\n",
    "        inputs = Input(input_size)\n",
    "\n",
    "        # Downsampling path\n",
    "        c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "        c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "        p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "        # Bottom (bottleneck)\n",
    "        c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "\n",
    "        # Upsampling path\n",
    "        u4 = UpSampling2D((2, 2))(c3)\n",
    "        u4 = concatenate([u4, c2])\n",
    "\n",
    "        u5 = UpSampling2D((2, 2))(u4)\n",
    "        u5 = concatenate([u5, c1])\n",
    "\n",
    "        c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u5)\n",
    "        outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "\n",
    "        model = Model(inputs=[inputs], outputs=[outputs])\n",
    "        return model\n",
    "\n",
    "    # Compile the model\n",
    "    model = unet_model()\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping and model checkpoint\n",
    "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "    model_checkpoint = ModelCheckpoint(os.path.join('models', 'best_model.keras'), save_best_only=True, monitor='val_loss')\n",
    "\n",
    "    # Training the model on CPU\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=10,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n"
   ],
   "id": "b5f1a5502a94693b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **4.  Comparaison des Modèles U-Net, VGG16-UNET, et U-Net Mini**",
   "id": "63bf1b5becc0baee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Explication :** Ici, nous avons ajouté un modèle U-Net Mini, qui est une version plus légère et simplifiée du U-Net. Le modèle VGG16-UNET a été mis à jour pour inclure une couche de data augmentation interne afin de mieux généraliser les performances.\n",
   "id": "4a679e3d2450a87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, RandomZoom, Conv2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Désactiver complètement les GPU pour exécuter uniquement sur le CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Développement du modèle VGG16-UNET\n",
    "def vgg16_unet_model(input_size=(256, 256, 3)):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_size)\n",
    "    \n",
    "    # Data augmentation intégrée\n",
    "    inputs = Input(input_size)\n",
    "    x = RandomFlip(\"horizontal\")(inputs)\n",
    "    x = RandomRotation(0.2)(x)\n",
    "    x = RandomZoom(0.2)(x)\n",
    "    \n",
    "    # Passage de l'entrée dans le modèle VGG16\n",
    "    block1_conv2 = base_model.get_layer('block1_conv2').output\n",
    "    block2_conv2 = base_model.get_layer('block2_conv2').output\n",
    "    block3_conv3 = base_model.get_layer('block3_conv3').output\n",
    "    vgg_outputs = [block1_conv2, block2_conv2, block3_conv3]\n",
    "    \n",
    "    # Définir un nouveau modèle avec les sorties intermédiaires désirées\n",
    "    vgg16_encoder = Model(inputs=base_model.input, outputs=vgg_outputs)\n",
    "    \n",
    "    # Passer les images par l'encodeur\n",
    "    c1, c2, c3 = vgg16_encoder(x)\n",
    "    \n",
    "    # Partie remontante du U-Net avec des couches de décodage\n",
    "    u4 = UpSampling2D((2, 2))(c3)\n",
    "    u4 = concatenate([u4, c2])\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(u4)\n",
    "    \n",
    "    u5 = UpSampling2D((2, 2))(c4)\n",
    "    u5 = concatenate([u5, c1])\n",
    "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u5)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialisation et compilation du modèle\n",
    "vgg16_model = vgg16_unet_model()\n",
    "vgg16_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Définition des callbacks\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "vgg16_checkpoint = ModelCheckpoint(os.path.join('models', 'vgg16_best_model.keras'), save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Entraînement du modèle VGG16-UNET uniquement sur le CPU\n",
    "def train_vgg16_on_cpu():\n",
    "    with tf.device('/CPU:0'):  # Spécifie l'utilisation explicite du CPU\n",
    "        vgg16_model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=10,\n",
    "            callbacks=[early_stopping, vgg16_checkpoint]\n",
    "        )\n",
    "\n",
    "# Appel de la fonction d'entraînement\n",
    "train_vgg16_on_cpu()\n"
   ],
   "id": "37abad2a56578448"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T18:04:00.039825100Z",
     "start_time": "2024-12-07T09:59:15.642864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Développement du modèle U-Net Mini\n",
    "def unet_mini_model(input_size=(256, 256, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Partie à la descente\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "\n",
    "    # Partie remontante\n",
    "    u4 = UpSampling2D((2, 2))(c3)\n",
    "    u4 = concatenate([u4, c2])\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(u4)\n",
    "\n",
    "    u5 = UpSampling2D((2, 2))(c4)\n",
    "    u5 = concatenate([u5, c1])\n",
    "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(u5)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "unet_mini_model = unet_mini_model()\n",
    "unet_mini_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle U-Net Mini\n",
    "def train_unet_mini_on_gpu():\n",
    "    with tf.device('/GPU:0'):\n",
    "        unet_mini_model.fit(train_gen, validation_data=val_gen, epochs=10, callbacks=[early_stopping, unet_mini_checkpoint])\n",
    "        \n",
    "unet_mini_model()        "
   ],
   "id": "475e859f6c01d268",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Conclusion, Comparaison et Visualisation des Modèles",
   "id": "2c159dc8ff591131"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "** Cette cellule compare les trois modèles entraînés (U-Net classique, VGG16-UNET, et U-Net Mini) sur les métriques telles que l'accuracy, l'IoU, et le Dice Coefficient. Des graphiques sont créés pour visualiser les performances de chaque modèle. ",
   "id": "902b1c9cc27a68a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:04:02.278031Z",
     "start_time": "2024-12-17T12:04:02.266120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vérification des générateurs\n",
    "print(f\"Nombre d'images dans test_gen : {len(test_gen)}\")\n",
    "print(f\"Nombre d'images dans val_gen : {len(val_gen)}\")\n",
    "\n",
    "# Si le générateur a des listes d'images et de masques, vérifie leur longueur\n",
    "if hasattr(test_gen, 'image_list') and hasattr(test_gen, 'mask_list'):\n",
    "    print(f\"Nombre d'images dans test_gen : {len(test_gen.image_list)}\")\n",
    "    print(f\"Nombre de masques dans test_gen : {len(test_gen.mask_list)}\")\n",
    "\n",
    "if hasattr(val_gen, 'image_list') and hasattr(val_gen, 'mask_list'):\n",
    "    print(f\"Nombre d'images dans val_gen : {len(val_gen.image_list)}\")\n",
    "    print(f\"Nombre de masques dans val_gen : {len(val_gen.mask_list)}\")"
   ],
   "id": "15408012575e3476",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images dans test_gen : 762\n",
      "Nombre d'images dans val_gen : 250\n",
      "Nombre d'images dans test_gen : 1525\n",
      "Nombre de masques dans test_gen : 1153\n",
      "Nombre d'images dans val_gen : 500\n",
      "Nombre de masques dans val_gen : 500\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "!pip show tensorflow keras\n",
   "id": "16b1ddcfa166a2f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:11:06.282100Z",
     "start_time": "2024-12-17T12:11:05.843871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# Charger les modèles sauvegardés\n",
    "unet_model_path = os.path.join('models', 'unet_best_model.keras')\n",
    "vgg16_model_path = os.path.join('models', 'vgg16_best_model.keras')\n",
    "unet_mini_model_path = os.path.join('models', 'unet_mini_best_model.keras')\n",
    "\n",
    "# Vérifier que les fichiers existent\n",
    "assert os.path.exists(unet_model_path), f\"Le modèle U-Net n'a pas été trouvé à {unet_model_path}\"\n",
    "assert os.path.exists(vgg16_model_path), f\"Le modèle VGG16-UNET n'a pas été trouvé à {vgg16_model_path}\"\n",
    "assert os.path.exists(unet_mini_model_path), f\"Le modèle U-Net Mini n'a pas été trouvé à {unet_mini_model_path}\"\n",
    "\n",
    "# Charger les modèles\n",
    "unet_model = load_model(unet_model_path)\n",
    "vgg16_model = load_model(vgg16_model_path)\n",
    "unet_mini_model = load_model(unet_mini_model_path)\n",
    "\n",
    "# Comparaison des performances des modèles\n",
    "def compare_models(models, val_gen, test_gen):\n",
    "    metrics = []\n",
    "    for model in models:\n",
    "        # Nom du modèle\n",
    "        model_name = model.name if hasattr(model, 'name') else 'Unnamed Model'\n",
    "\n",
    "        # Évaluation sur l'ensemble de validation\n",
    "        print(f\"Évaluation sur l'ensemble de validation pour le modèle: {model_name}\")\n",
    "        loss, accuracy = model.evaluate(val_gen, verbose=0)\n",
    "\n",
    "        # Prédictions sur l'ensemble de test\n",
    "        print(f\"Prédictions sur l'ensemble de test pour le modèle: {model_name}\")\n",
    "        y_pred = model.predict(test_gen, verbose=0)\n",
    "        y_pred_binary = (y_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "        # Récupérer les vraies étiquettes de l'ensemble de test\n",
    "        y_test = np.concatenate([y for _, y in test_gen], axis=0)\n",
    "\n",
    "        # Calcul de l'IoU (Intersection over Union)\n",
    "        intersection = np.logical_and(y_test, y_pred_binary).sum()\n",
    "        union = np.logical_or(y_test, y_pred_binary).sum()\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "\n",
    "        # Calcul du coefficient de Dice\n",
    "        dice = (2 * intersection) / (y_test.sum() + y_pred_binary.sum()) if (y_test.sum() + y_pred_binary.sum()) > 0 else 0\n",
    "\n",
    "        # Ajouter les métriques du modèle à la liste\n",
    "        metrics.append({\n",
    "            'model': model_name,\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy,\n",
    "            'iou': iou,\n",
    "            'dice': dice\n",
    "        })\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Liste des modèles à comparer\n",
    "models = [unet_model, vgg16_model, unet_mini_model]\n",
    "\n",
    "# Comparer les modèles\n",
    "metrics = compare_models(models, val_gen, test_gen)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"\\nRésumé des performances des modèles :\")\n",
    "for metric in metrics:\n",
    "    print(f\"Model: {metric['model']}\")\n",
    "    print(f\"  Loss: {metric['loss']:.4f}\")\n",
    "    print(f\"  Accuracy: {metric['accuracy']:.4f}\")\n",
    "    print(f\"  IoU: {metric['iou']:.4f}\")\n",
    "    print(f\"  Dice: {metric['dice']:.4f}\")"
   ],
   "id": "80d30139eb3920b9",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not deserialize class 'Functional' because its parent module keras.src.models.functional cannot be imported. Full object config: {'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional_1', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 256, 256, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}, 'registered_name': None, 'name': 'input_layer_1', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 3]}, 'name': 'conv2d_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 3], 'dtype': 'float32', 'keras_history': ['input_layer_1', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 16]}, 'name': 'max_pooling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 16]}, 'name': 'conv2d_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 16], 'dtype': 'float32', 'keras_history': ['max_pooling2d_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 32]}, 'name': 'max_pooling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64, 32]}, 'name': 'conv2d_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 64, 64, 32], 'dtype': 'float32', 'keras_history': ['max_pooling2d_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'UpSampling2D', 'config': {'name': 'up_sampling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'size': [2, 2], 'data_format': 'channels_last', 'interpolation': 'nearest'}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64, 128]}, 'name': 'up_sampling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 64, 64, 128], 'dtype': 'float32', 'keras_history': ['conv2d_8', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 128, 128, 128], [None, 128, 128, 32]]}, 'name': 'concatenate_2', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 128], 'dtype': 'float32', 'keras_history': ['up_sampling2d_2', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 160]}, 'name': 'conv2d_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 160], 'dtype': 'float32', 'keras_history': ['concatenate_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'UpSampling2D', 'config': {'name': 'up_sampling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'size': [2, 2], 'data_format': 'channels_last', 'interpolation': 'nearest'}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 32]}, 'name': 'up_sampling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_9', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 256, 256, 32], [None, 256, 256, 16]]}, 'name': 'concatenate_3', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 32], 'dtype': 'float32', 'keras_history': ['up_sampling2d_3', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 48]}, 'name': 'conv2d_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 48], 'dtype': 'float32', 'keras_history': ['concatenate_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 1, 'kernel_size': [1, 1], 'strides': [1, 1], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 16]}, 'name': 'conv2d_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_10', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer_1', 0, 0]], 'output_layers': [['conv2d_11', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'binary_crossentropy', 'loss_weights': None, 'metrics': ['accuracy'], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:776\u001B[0m, in \u001B[0;36m_retrieve_class_or_fn\u001B[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001B[0m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 776\u001B[0m     mod \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1050\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1004\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'keras.src.models.functional'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(unet_mini_model_path), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLe modèle U-Net Mini n\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma pas été trouvé à \u001B[39m\u001B[38;5;132;01m{\u001B[39;00munet_mini_model_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Charger les modèles\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m unet_model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43munet_model_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m vgg16_model \u001B[38;5;241m=\u001B[39m load_model(vgg16_model_path)\n\u001B[0;32m     18\u001B[0m unet_mini_model \u001B[38;5;241m=\u001B[39m load_model(unet_mini_model_path)\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:230\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[0;32m    226\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    227\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe following argument(s) are not supported \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    228\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith the native Keras format: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    229\u001B[0m         )\n\u001B[1;32m--> 230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msaving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m        \u001B[49m\u001B[43msafe_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m legacy_sm_saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    239\u001B[0m     filepath, custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects, \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    240\u001B[0m )\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:275\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    272\u001B[0m             asset_store\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 275\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    276\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:240\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;66;03m# Construct the model from the configuration file in the archive.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ObjectSharingScope():\n\u001B[1;32m--> 240\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_mode\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    244\u001B[0m all_filenames \u001B[38;5;241m=\u001B[39m zf\u001B[38;5;241m.\u001B[39mnamelist()\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _VARS_FNAME \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m all_filenames:\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:681\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[1;34m(config, custom_objects, safe_mode, **kwargs)\u001B[0m\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    679\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[1;32m--> 681\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43m_retrieve_class_or_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    682\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    683\u001B[0m \u001B[43m    \u001B[49m\u001B[43mregistered_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    684\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mclass\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    686\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfull_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    688\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mcls\u001B[39m, types\u001B[38;5;241m.\u001B[39mFunctionType):\n\u001B[0;32m    691\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\test_env\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:778\u001B[0m, in \u001B[0;36m_retrieve_class_or_fn\u001B[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001B[0m\n\u001B[0;32m    776\u001B[0m     mod \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(module)\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n\u001B[1;32m--> 778\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    779\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not deserialize \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobj_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m because \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    780\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mits parent module \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m cannot be imported. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    781\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFull object config: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_config\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    782\u001B[0m     )\n\u001B[0;32m    783\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mvars\u001B[39m(mod)\u001B[38;5;241m.\u001B[39mget(name, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    785\u001B[0m \u001B[38;5;66;03m# Special case for keras.metrics.metrics\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: Could not deserialize class 'Functional' because its parent module keras.src.models.functional cannot be imported. Full object config: {'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional_1', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 256, 256, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}, 'registered_name': None, 'name': 'input_layer_1', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 3]}, 'name': 'conv2d_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 3], 'dtype': 'float32', 'keras_history': ['input_layer_1', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 16]}, 'name': 'max_pooling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 16]}, 'name': 'conv2d_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 16], 'dtype': 'float32', 'keras_history': ['max_pooling2d_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 32]}, 'name': 'max_pooling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64, 32]}, 'name': 'conv2d_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 64, 64, 32], 'dtype': 'float32', 'keras_history': ['max_pooling2d_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'UpSampling2D', 'config': {'name': 'up_sampling2d_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'size': [2, 2], 'data_format': 'channels_last', 'interpolation': 'nearest'}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64, 128]}, 'name': 'up_sampling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 64, 64, 128], 'dtype': 'float32', 'keras_history': ['conv2d_8', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 128, 128, 128], [None, 128, 128, 32]]}, 'name': 'concatenate_2', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 128], 'dtype': 'float32', 'keras_history': ['up_sampling2d_2', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 160]}, 'name': 'conv2d_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 160], 'dtype': 'float32', 'keras_history': ['concatenate_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'UpSampling2D', 'config': {'name': 'up_sampling2d_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'size': [2, 2], 'data_format': 'channels_last', 'interpolation': 'nearest'}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 128, 32]}, 'name': 'up_sampling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 128, 32], 'dtype': 'float32', 'keras_history': ['conv2d_9', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 256, 256, 32], [None, 256, 256, 16]]}, 'name': 'concatenate_3', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 32], 'dtype': 'float32', 'keras_history': ['up_sampling2d_3', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 48]}, 'name': 'conv2d_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 48], 'dtype': 'float32', 'keras_history': ['concatenate_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 139852018551200}, 'filters': 1, 'kernel_size': [1, 1], 'strides': [1, 1], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 256, 256, 16]}, 'name': 'conv2d_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 256, 256, 16], 'dtype': 'float32', 'keras_history': ['conv2d_10', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer_1', 0, 0]], 'output_layers': [['conv2d_11', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'binary_crossentropy', 'loss_weights': None, 'metrics': ['accuracy'], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualisation des résultats\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(metrics_df['model'], metrics_df['accuracy'], label='Accuracy', marker='o')\n",
    "plt.plot(metrics_df['model'], metrics_df['iou'], label='IoU', marker='o')\n",
    "plt.plot(metrics_df['model'], metrics_df['dice'], label='Dice Coefficient', marker='o')\n",
    "plt.title('Comparaison des métriques entre modèles')\n",
    "plt.xlabel('Modèles')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(metrics_df['model'], metrics_df['loss'], color='red')\n",
    "plt.title('Loss des différents modèles')\n",
    "plt.xlabel('Modèles')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "id": "74f61c9f0a7f5089"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualisation des exemples de résultats pour chaque modèle",
   "id": "6b639662d5040db4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fonction de visualisation des prédictions\n",
    "\n",
    "def visualize_predictions(models, test_gen, num_examples=3):\n",
    "    for model in models:\n",
    "        print(f\"Visualisation des prédictions pour le modèle: {model.name}\")\n",
    "        predictions = model.predict(test_gen)\n",
    "        X_test, y_test = next(iter(test_gen))\n",
    "        for i in range(num_examples):\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(X_test[i])\n",
    "            plt.title(\"Image d'origine\")\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(y_test[i].squeeze(), cmap='gray')\n",
    "            plt.title(\"Masque réel\")\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "            plt.title(\"Masque prédit\")\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "# Visualiser quelques exemples de segmentation\n",
    "visualize_predictions(models, test_gen)"
   ],
   "id": "edd80304a6ea4d2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
